{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Code for the AIMO competition of Kaggle.\n",
        "### Based on Deepseek Math's Group Relative Policy Optimization (GRPO) concept"
      ],
      "metadata": {
        "id": "3EErXTEO6Kad"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVInlAwz6BlM"
      },
      "outputs": [],
      "source": [
        "!pip install  -U -q trl peft math_verify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()\n",
        "\n",
        "import time\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import re\n",
        "from math_verify import LatexExtractionConfig, parse, verify\n",
        "from trl import GRPOConfig, GRPOTrainer"
      ],
      "metadata": {
        "id": "QBSOtpwr6EoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_id = 'AI-MO/NuminaMath-TIR'\n",
        "train_dataset, test_dataset = load_dataset(dataset_id, split=['train[:5%]', 'test[:5%]'])"
      ],
      "metadata": {
        "id": "UygMJuSd6VM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = (\n",
        "    \"A conversation between User and Assistant. The user asks a question, and the Assistant solves it. The assistant \"\n",
        "    \"first thinks about the reasoning process in the mind and then provides the user with the answer. The reasoning \"\n",
        "    \"process and answer are enclosed within   and   tags, respectively, i.e., \"\n",
        "    \" reasoning process here  answer here \"\n",
        ")\n",
        "\n",
        "def make_conversation(example):\n",
        "    return {\n",
        "        \"prompt\": [\n",
        "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "            {\"role\": \"user\", \"content\": example[\"problem\"]},\n",
        "        ],\n",
        "    }\n",
        "\n",
        "train_dataset = train_dataset.map(make_conversation)\n",
        "test_dataset = test_dataset.map(make_conversation)"
      ],
      "metadata": {
        "id": "HRjxOARz6ffl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.remove_columns(['messages', 'problem'])\n",
        "print(train_dataset)"
      ],
      "metadata": {
        "id": "D7xJom7Y6hbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"Qwen/Qwen2-0.5B-Instruct\"\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "0lLZBVVJ6j7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1,\n",
        "    target_modules=[\"q_proj\", \"v_proj\"],\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "UmNMWgz96pv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
        "    pattern = r\"^.*?\\s*.*?$\"\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    matches = [re.match(pattern, content) for content in completion_contents]\n",
        "    rewards_list = [1.0 if match else 0.0 for match in matches]\n",
        "    return [1.0 if match else 0.0 for match in matches]"
      ],
      "metadata": {
        "id": "u1OXGCSq6tX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_reward(completions, **kwargs):\n",
        "    \"\"\"Reward function that checks if the completion is the same as the ground truth.\"\"\"\n",
        "    solutions = kwargs['solution']\n",
        "    completion_contents = [completion[0][\"content\"] for completion in completions]\n",
        "    rewards = []\n",
        "    for content, solution in zip(completion_contents, solutions):\n",
        "        gold_parsed = parse(solution, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
        "        answer_parsed = parse(content, extraction_mode=\"first_match\", extraction_config=[LatexExtractionConfig()])\n",
        "        if len(gold_parsed) != 0:\n",
        "            try:\n",
        "                rewards.append(float(verify(answer_parsed, gold_parsed)))\n",
        "            except Exception:\n",
        "                rewards.append(0.0)\n",
        "        else:\n",
        "            rewards.append(1.0)\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "gb6fF_K96wkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = GRPOConfig(\n",
        "    output_dir=\"Qwen2-0.5B-GRPO-test\",\n",
        "    learning_rate=1e-5,\n",
        "    remove_unused_columns=False, # to access the solution column in accuracy_reward\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_train_epochs=1,\n",
        "    bf16=True,\n",
        "\n",
        "    # Parameters that control de data preprocessing\n",
        "    max_completion_length=64, # default: 256\n",
        "    num_generations=4, # default: 8\n",
        "    max_prompt_length=128, # default: 512\n",
        "\n",
        "    # Parameters related to reporting and saving\n",
        "    report_to=[\"tensorboard\"],\n",
        "    logging_steps=10,\n",
        "    push_to_hub=True,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=10,\n",
        ")"
      ],
      "metadata": {
        "id": "20H4DZUb6zzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    reward_funcs=[format_reward, accuracy_reward],\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset\n",
        ")"
      ],
      "metadata": {
        "id": "USziW2ky65Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "nya0_m-766T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(training_args.output_dir)\n",
        "trainer.push_to_hub(dataset_name=dataset_id)"
      ],
      "metadata": {
        "id": "oJ250D8f68W0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"sergiopaniego/Qwen2-0.5B-GRPO\"\n",
        "trained_model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        ")\n",
        "trained_tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "yJFypGCk69uF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_with_reasoning(prompt):\n",
        "  # Build the prompt from the dataset\n",
        "  prompt = \" \".join(entry['content'] for entry in prompt)\n",
        "\n",
        "  # Tokenize and move to the same device as the model\n",
        "  inputs = trained_tokenizer(prompt, return_tensors=\"pt\").to(trained_model.device)\n",
        "\n",
        "  # Generate text without gradients\n",
        "  start_time = time.time()\n",
        "  with torch.no_grad():\n",
        "      output_ids = trained_model.generate(**inputs, max_length=500)\n",
        "  end_time = time.time()\n",
        "\n",
        "  # Decode and extract model response\n",
        "  generated_text = trained_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "\n",
        "  # Get inference time\n",
        "  inference_duration = end_time - start_time\n",
        "\n",
        "  # Get number of generated tokens\n",
        "  num_input_tokens = inputs['input_ids'].shape[1]\n",
        "  num_generated_tokens = output_ids.shape[1] - num_input_tokens\n",
        "\n",
        "  return generated_text, inference_duration, num_generated_tokens\n",
        ""
      ],
      "metadata": {
        "id": "C5gpxKA87G01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = test_dataset['prompt'][0]\n",
        "generated_text, inference_duration, num_generated_tokens = generate_with_reasoning(prompt)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "id": "G29vvspk7Jpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Inference time: {inference_duration:.2f} seconds\")\n",
        "print(f\"Generated tokens: {num_generated_tokens}\")"
      ],
      "metadata": {
        "id": "QJ2-cWvd7Ld0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_text = \" \".join(entry['content'] for entry in prompt)\n",
        "response_text = generated_text[len(prompt_text):].strip()\n",
        "print(response_text)"
      ],
      "metadata": {
        "id": "VVj9m4O17Oes"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}